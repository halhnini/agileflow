# âš¡ AgileFlow

**Sprint intelligence that runs itself.**

AgileFlow automates stand-ups, tracks sprint health, detects tech debt, and generates AI-powered insights â€” so your team can just code.

## Features

| Module | What It Does |
|---|---|
| ğŸ“Š AI Activity Analysis | Generates async stand-ups from commit history |
| ğŸ”„ Smart Board Sync | Maps commits to tickets with 95% confidence |
| â¤ï¸ Health Score | Real-time project health (0-100) |
| ğŸ›¡ï¸ Tech Debt Sentinel | Auto-generates refactor tickets from diff analysis |
| ğŸ“ˆ Velocity Forecast | Predicts sprint risk with scope recommendations |
| ğŸ§  AI Sprint Narrative | LLM-powered natural language sprint reports |

## Quick Start

```bash
# Run with mock AI (no API key needed)
docker build -t agileflow ./ghost_scrum_master
docker run --rm agileflow

# Run with a real LLM
docker run --rm \
  -e LLM_PROVIDER=gemini \
  -e LLM_API_KEY=your-key \
  agileflow
```

## Supported LLM Providers

| Provider | Env Variable | Default Model |
|---|---|---|
| OpenAI | `LLM_PROVIDER=openai` | gpt-4o-mini |
| Google Gemini | `LLM_PROVIDER=gemini` | gemini-2.0-flash |
| Ollama (local) | `LLM_PROVIDER=ollama` | llama3 |
| Mock (demo) | `LLM_PROVIDER=mock` | â€” |

## Project Structure

```
â”œâ”€â”€ ghost_scrum_master/     # Core engine
â”‚   â”œâ”€â”€ main.py             # Unified dashboard (v5.0)
â”‚   â”œâ”€â”€ Dockerfile          # Production container
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ llm_client.py   # Provider-agnostic LLM interface
â”‚   â”‚   â”œâ”€â”€ ai_analyser.py  # AI reasoning engine
â”‚   â”‚   â”œâ”€â”€ predictive.py   # Health scoring
â”‚   â”‚   â”œâ”€â”€ debt_sentinel.py # Tech debt detection
â”‚   â”‚   â””â”€â”€ velocity.py     # Sprint forecasting
â”‚   â””â”€â”€ mocks/              # Demo data
â””â”€â”€ landing/                # Marketing site
    â”œâ”€â”€ index.html
    â””â”€â”€ style.css
```

## License

MIT
